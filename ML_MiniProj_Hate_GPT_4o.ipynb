{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-O-KTxkynd6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93b04f12-1c50-413d-c270-43dd5636f166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.3/358.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.8/644.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain langchain-community gradio_client python-dotenv langsmith transformers torch tensorflow tf_keras scikit-learn openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jloG1RtZndBR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from gradio_client import Client, handle_file\n",
        "from langsmith import traceable\n",
        "from dotenv import load_dotenv\n",
        "from typing import Union, List, Dict, Any\n",
        "import json\n",
        "import mimetypes\n",
        "import logging\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "2hc6r3injY3J"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "mBjw-HPAjY3J"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "API_KEY = userdata.get('SVAI_OPENAI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUtatAo-jY3J",
        "outputId": "b33a2b34-f6bb-45ec-9385-bd2cb191ca72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "classifier = pipeline(\"text-classification\", model=model_id, top_k=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "pwE2QEwTqJYI"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-4o\",\n",
        "    # base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=API_KEY,\n",
        "    temperature=0.3,\n",
        "    max_tokens=1024,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "OviEf0T2jY3J"
      },
      "outputs": [],
      "source": [
        "def create_client(client_id: str) -> Client:\n",
        "    return Client(client_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "XN33j9YkjY3K"
      },
      "outputs": [],
      "source": [
        "@traceable\n",
        "def run_text_model(text: str, client_id: str) -> str:\n",
        "    try:\n",
        "        client = create_client(client_id)\n",
        "        label, score = client.predict(text, api_name=\"/predict\")\n",
        "        return f\"Prediction: {label} with a score of {score}\"\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in text model {client_id}: {e}\")\n",
        "        return f\"Error: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "STo808GfjY3K"
      },
      "outputs": [],
      "source": [
        "@traceable\n",
        "def run_hinglish_hate_model(text: str) -> str:\n",
        "    return run_text_model(text, \"dj-dawgs-ipd/IPD-Hinglish-Text-Model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GYVrAwJRjY3K"
      },
      "outputs": [],
      "source": [
        "@traceable\n",
        "def run_english_hate_model(text: str) -> str:\n",
        "    return run_text_model(text, \"dj-dawgs-ipd/IPD-Text-English-Finetune\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "1SQjBuCvjY3K"
      },
      "outputs": [],
      "source": [
        "@traceable\n",
        "def run_image_hate_model(image_path: str) -> str:\n",
        "    try:\n",
        "        client = Client(\"dj-dawgs-ipd/IPD_IMAGE_PIPELINE\")\n",
        "        result = client.predict(handle_file(image_path), api_name=\"/predict\")\n",
        "        return f\"Image Analysis Result: {result}\"\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in image model: {e}\")\n",
        "        return f\"Error calling Image model: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sgXOVQ22jY3K"
      },
      "outputs": [],
      "source": [
        "@traceable\n",
        "def run_audio_hate_model(audio_path: str) -> str:\n",
        "    try:\n",
        "        client = Client(\"dj-dawgs-ipd/IPD-Audio-Pipeline\")\n",
        "        result = client.predict(handle_file(audio_path), api_name=\"/predict\")\n",
        "        return f\"Audio Analysis Result: {result}\"\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in audio model: {e}\")\n",
        "        return f\"Error calling Audio model: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uIAAS6dmjY3K"
      },
      "outputs": [],
      "source": [
        "@traceable\n",
        "def run_sentiment_analysis(text: str) -> str:\n",
        "    try:\n",
        "        prediction = classifier(text)\n",
        "        return prediction\n",
        "        # client = Client(\"https://ck42-sentiment-model-comparison.hf.space/--replicas/ftdum/\")\n",
        "        # sentiment_data = client.predict(text, api_name=\"/predict_2\")\n",
        "        # if isinstance(sentiment_data, list) and all(isinstance(item, (list, tuple)) for item in sentiment_data):\n",
        "        #     formatted_sentiments = \", \".join(\n",
        "        #         [f\"{sentiment} ({score:.2f})\" for sentiment, score in sentiment_data]\n",
        "        #     )\n",
        "        # else:\n",
        "        #     formatted_sentiments = str(sentiment_data)\n",
        "        # return f\"Sentiment Analysis: {formatted_sentiments}\"\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in sentiment analysis: {e}\")\n",
        "        return f\"Error: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FRQvIl6MqNdF"
      },
      "outputs": [],
      "source": [
        "hinglish_tool = Tool.from_function(\n",
        "    func=run_hinglish_hate_model,\n",
        "    name=\"HinglishHateChecker\",\n",
        "    description=\"Detects hate speech in Hinglish text.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VLUI69gJjY3K"
      },
      "outputs": [],
      "source": [
        "english_tool = Tool.from_function(\n",
        "    func=run_english_hate_model,\n",
        "    name=\"EnglishHateChecker\",\n",
        "    description=\"Detects hate speech in English text.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dOgh5O6UjY3K"
      },
      "outputs": [],
      "source": [
        "image_tool = Tool.from_function(\n",
        "    func=run_image_hate_model,\n",
        "    name=\"ImageHateChecker\",\n",
        "    description=\"Detects hate symbols or hateful content in images.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tUbLAYFAjY3K"
      },
      "outputs": [],
      "source": [
        "audio_tool = Tool.from_function(\n",
        "    func=run_audio_hate_model,\n",
        "    name=\"AudioHateChecker\",\n",
        "    description=\"Detects hate speech in audio files.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BO4tA5TMjY3K"
      },
      "outputs": [],
      "source": [
        "sentiment_tool = Tool.from_function(\n",
        "    func=run_sentiment_analysis,\n",
        "    name=\"SentimentAnalyzer\",\n",
        "    description=\"Analyzes the sentiment of text to assess emotional tone.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "6oSum6RFqWqI"
      },
      "outputs": [],
      "source": [
        "tools = [hinglish_tool, english_tool, image_tool, audio_tool, sentiment_tool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "brGpSceMjY3L"
      },
      "outputs": [],
      "source": [
        "def detect_modality(input_data: Union[str, os.PathLike]) -> str:\n",
        "    if isinstance(input_data, str):\n",
        "        if os.path.exists(input_data):\n",
        "            mime_type, _ = mimetypes.guess_type(input_data)\n",
        "            if mime_type:\n",
        "                if mime_type.startswith(\"image\"):\n",
        "                    return \"image\"\n",
        "                elif mime_type.startswith(\"audio\"):\n",
        "                    return \"audio\"\n",
        "            return \"unknown\"\n",
        "        else:\n",
        "            return \"text\"\n",
        "    return \"unknown\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "cHXZKLYFqa5e"
      },
      "outputs": [],
      "source": [
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "tVZFgmBtjY3L"
      },
      "outputs": [],
      "source": [
        "@traceable\n",
        "def pipeline(input_data: Union[str, os.PathLike]):\n",
        "    modality = detect_modality(input_data)\n",
        "    system_instruction = f\"\"\"\n",
        "You are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\n",
        "\n",
        "Modality Detected: {modality}\n",
        "\n",
        "Use the following tools as applicable:\n",
        "- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\n",
        "- For image files: use the ImageHateChecker.\n",
        "- For audio files: use the AudioHateChecker.\n",
        "\n",
        "Instructions:\n",
        "1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\n",
        "2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\n",
        "4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\n",
        "   - \"Hate Speech: Yes\" or \"Hate Speech: No\"\n",
        "   - Followed by \"— Reason:\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\n",
        "\n",
        "Final Output Format:\n",
        "\"Hate Speech: Yes/No — Reason: <your detailed explanation with all tool outputs and reasoning>\"\n",
        "\n",
        "IMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\n",
        "SOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\n",
        "\n",
        "Now, process the following input:\n",
        "Input: {input_data}\n",
        "\"\"\"\n",
        "    prompt = f\"{system_instruction}\\n\\nInput: {input_data}\"\n",
        "    return agent.invoke(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7UjUuLMnayr",
        "outputId": "8bd7f2be-6974-4fd2-c02e-bb90aa5ccaf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo determine if the image \"swastika.png\" contains hate speech or symbols, I need to analyze the image using the appropriate tool for detecting hate content in images.\n",
            "\n",
            "Action: ImageHateChecker\n",
            "Action Input: swastika.png\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-image-pipeline.hf.space ✔\n",
            "\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mImage Analysis Result: {'prediction': 'not_hate', 'language': None, 'label': 'No hate found, yay!', 'confidence': None, 'hate_text': None}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe ImageHateChecker tool has analyzed the image \"swastika.png\" and returned a result indicating \"not_hate\" with the label \"No hate found, yay!\" This suggests that the tool did not detect any hate symbols or hateful content in the image. However, it is important to consider the context and potential symbolic meanings associated with the swastika.\n",
            "\n",
            "The swastika is a symbol with a complex history. It has been used for thousands of years in various cultures as a symbol of good fortune and well-being. However, in the 20th century, it was appropriated by the Nazi regime in Germany and became associated with hate, racism, and anti-Semitism. Therefore, the interpretation of the swastika can vary greatly depending on the context in which it is used.\n",
            "\n",
            "Given the tool's output and the historical context of the swastika, it is crucial to consider the specific context in which the image is presented. If the image is used in a context that promotes hate or discrimination, it could be considered hate speech. Conversely, if it is used in a cultural or historical context that reflects its original meaning, it may not be considered hate speech.\n",
            "\n",
            "Final Answer: Hate Speech: No — Reason: The ImageHateChecker tool did not detect any hate symbols in the image \"swastika.png.\" While the swastika has been used as a hate symbol in certain contexts, the tool's analysis suggests that this particular image does not contain hate content. The interpretation of the swastika depends on its context, which is not provided here.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': '\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: image\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \"Hate Speech: Yes\" or \"Hate Speech: No\"\\n   - Followed by \"— Reason:\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\"Hate Speech: Yes/No — Reason: <your detailed explanation with all tool outputs and reasoning>\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: swastika.png\\n\\n\\nInput: swastika.png', 'output': 'Hate Speech: No — Reason: The ImageHateChecker tool did not detect any hate symbols in the image \"swastika.png.\" While the swastika has been used as a hate symbol in certain contexts, the tool\\'s analysis suggests that this particular image does not contain hate content. The interpretation of the swastika depends on its context, which is not provided here.'}\n"
          ]
        }
      ],
      "source": [
        "# print(pipeline(\"chutiyo logo ko mumbai me lena hi nhi chahiye\"))\n",
        "print(pipeline(\"swastika.png\"))\n",
        "# print(pipeline(\"hate_audio.wav\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "YI0E7lYIjY3L"
      },
      "outputs": [],
      "source": [
        "@traceable\n",
        "def evaluate_pipeline(test_dataset: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "    results = []\n",
        "    for example in test_dataset:\n",
        "        inp = example.get(\"input\")\n",
        "        expected = example.get(\"expected\", \"N/A\")\n",
        "        output = pipeline(inp)\n",
        "        result = {\n",
        "            \"input\": inp,\n",
        "            \"expected\": expected,\n",
        "            \"output\": output,\n",
        "            \"modality\": detect_modality(inp)\n",
        "        }\n",
        "        results.append(result)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "It8jSeQljY3L"
      },
      "outputs": [],
      "source": [
        "import psutil\n",
        "import time\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "def extended_evaluate_pipeline(test_dataset: List[Dict[str, Any]], compute_metrics: bool = True):\n",
        "    results = []\n",
        "    predictions = []\n",
        "    ground_truths = []\n",
        "\n",
        "    for example in test_dataset:\n",
        "        inp = example.get(\"input\")\n",
        "        expected = example.get(\"expected\")  # e.g., \"Yes\" or \"No\"\n",
        "\n",
        "        process = psutil.Process(os.getpid())\n",
        "        mem_before = process.memory_info().rss\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        output = pipeline(inp)\n",
        "        end_time = time.perf_counter()\n",
        "        processing_time = end_time - start_time\n",
        "\n",
        "        mem_after = process.memory_info().rss\n",
        "        mem_used = mem_after - mem_before\n",
        "\n",
        "        # Assume output follows: \"Hate Speech: Yes — Reason: <...>\"\n",
        "        predicted = \"Unknown\"\n",
        "        if \"Hate Speech:\" in output:\n",
        "            try:\n",
        "                predicted = output.split(\"Hate Speech:\")[1].split(\"—\")[0].strip()\n",
        "            except Exception:\n",
        "                predicted = output.split(\"Hate Speech:\")[1].strip()\n",
        "\n",
        "        result = {\n",
        "            \"input\": inp,\n",
        "            \"expected\": expected,\n",
        "            \"output\": output,\n",
        "            \"predicted\": predicted,\n",
        "            \"processing_time\": processing_time,\n",
        "            \"memory_used_bytes\": mem_used,\n",
        "            \"modality\": detect_modality(inp)\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "        if expected is not None:\n",
        "            ground_truths.append(expected)\n",
        "            predictions.append(predicted)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "oYR8bKTQjY3L"
      },
      "outputs": [],
      "source": [
        "test_dataset = [\n",
        "    {\"input\": \"chutiyo logo ko mumbai me lena hi nhi chahiye\", \"expected\": \"Yes\"},\n",
        "    {\"input\": \"I love the diverse culture of this city\", \"expected\": \"No\"},\n",
        "    {\"input\": \"swastika.png\", \"expected\": \"Yes\"},\n",
        "    {\"input\": \"hate_audio.wav\", \"expected\": \"Yes\"},\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKKzoJjKjY3L",
        "outputId": "394a4cc3-f75c-46b2-9a73-e6feeb4027a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe input text appears to be in Hinglish, which is a mix of Hindi and English. The text seems to contain a derogatory term \"chutiyo,\" which is often used as an insult in Hindi. The sentence suggests that certain people should not be allowed in Mumbai, which could imply a discriminatory sentiment.\n",
            "\n",
            "Action: HinglishHateChecker\n",
            "Action Input: chutiyo logo ko mumbai me lena hi nhi chahiye\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-hinglish-text-model.hf.space ✔\n",
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mPrediction: OAG with a score of 0.9616120457649231\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe output from the HinglishHateChecker indicates a high likelihood of hate speech with a score of 0.9616. The term \"chutiyo\" is a derogatory term in Hindi, and the statement suggests exclusion of certain people from Mumbai, which can be considered discriminatory.\n",
            "\n",
            "Final Answer: Hate Speech: Yes — Reason: The input text contains a derogatory term \"chutiyo\" and suggests that certain people should not be allowed in Mumbai, which implies a discriminatory and exclusionary sentiment. The HinglishHateChecker also indicates a high likelihood of hate speech with a score of 0.9616, supporting the conclusion that this text constitutes hate speech.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe input is a text in English. To determine if it constitutes hate speech, I will use the EnglishHateChecker to detect any hate content and the SentimentAnalyzer to analyze the sentiment of the text.\n",
            "\n",
            "Action: EnglishHateChecker\n",
            "Action Input: I love the diverse culture of this city\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-english-text-model.hf.space ✔\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mPrediction: NEITHER with a score of 0.9985595345497131\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe EnglishHateChecker indicates that the text is neither hate speech nor offensive, with a high confidence score. To further understand the emotional tone of the text, I will use the SentimentAnalyzer.\n",
            "\n",
            "Action: SentimentAnalyzer\n",
            "Action Input: I love the diverse culture of this city\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m[[{'label': 'POSITIVE', 'score': 0.9998651742935181}, {'label': 'NEGATIVE', 'score': 0.00013480843335855752}]]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe SentimentAnalyzer shows that the text has a highly positive sentiment, with an almost negligible negative score. Combining this with the output from the EnglishHateChecker, which indicates that the text is neither hate speech nor offensive, I can conclude that the text is not hate speech.\n",
            "\n",
            "Final Answer: Hate Speech: No — Reason: The text \"I love the diverse culture of this city\" is identified as having a positive sentiment and is not classified as hate speech by the EnglishHateChecker. The sentiment analysis further supports this by showing a strong positive sentiment, indicating appreciation and admiration for cultural diversity.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo determine if the image \"swastika.png\" contains hate speech or symbols, I should use the ImageHateChecker tool, as it is designed to detect hate symbols or hateful content in images.\n",
            "\n",
            "Action: ImageHateChecker\n",
            "Action Input: swastika.png\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-image-pipeline.hf.space ✔\n",
            "\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mImage Analysis Result: {'prediction': 'not_hate', 'language': None, 'label': 'No hate found, yay!', 'confidence': None, 'hate_text': None}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe ImageHateChecker tool has analyzed the image \"swastika.png\" and returned a result indicating \"not_hate\" with the label \"No hate found, yay!\". This suggests that the image does not contain any recognized hate symbols or hateful content according to the tool's assessment.\n",
            "\n",
            "Final Answer: Hate Speech: No — Reason: The ImageHateChecker tool did not detect any hate symbols or hateful content in the image \"swastika.png\". The tool's output labeled the image as containing \"No hate found,\" indicating that it does not constitute hate speech based on the tool's analysis.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo analyze the input, which is an audio file, I should use the AudioHateChecker tool to detect any hate speech present in the audio.\n",
            "\n",
            "Action: AudioHateChecker\n",
            "Action Input: hate_audio.wav\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-audio-pipeline.hf.space ✔\n",
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mAudio Analysis Result: {'prediction': 'hate', 'language': 'Hinglish', 'label': None, 'confidence': 0.500702957312266, 'hate_text': 'that they have flash type of shows and turf war or gosh or ah yes ah ah the can share say that where i want one that i were you wish to how the flu or shop on oh oh oh oh oh oh oh the long haul'}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe AudioHateChecker tool has analyzed the audio file and returned a prediction of \"hate\" with a confidence level of approximately 0.5007. The language detected is Hinglish, and the transcribed text suggests aggressive or potentially harmful content. However, the confidence level is relatively low, indicating some uncertainty in the prediction.\n",
            "\n",
            "Final Answer: Hate Speech: Yes — Reason: The AudioHateChecker tool predicts the presence of hate speech in the audio file with a confidence level of 0.5007. The detected language is Hinglish, and the transcribed content suggests aggressive or potentially harmful language. Despite the low confidence level, the prediction leans towards the presence of hate speech, warranting a cautious approach.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "eval_results = evaluate_pipeline(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGnHTmNljY3M",
        "outputId": "d6822442-3995-48ba-c637-0fe18ef83782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results:\n",
            "{\n",
            "  \"input\": \"chutiyo logo ko mumbai me lena hi nhi chahiye\",\n",
            "  \"expected\": \"Yes\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: text\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \\\"Hate Speech: Yes\\\" or \\\"Hate Speech: No\\\"\\n   - Followed by \\\"\\u2014 Reason:\\\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <your detailed explanation with all tool outputs and reasoning>\\\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: chutiyo logo ko mumbai me lena hi nhi chahiye\\n\\n\\nInput: chutiyo logo ko mumbai me lena hi nhi chahiye\",\n",
            "    \"output\": \"Hate Speech: Yes \\u2014 Reason: The input text contains a derogatory term \\\"chutiyo\\\" and suggests that certain people should not be allowed in Mumbai, which implies a discriminatory and exclusionary sentiment. The HinglishHateChecker also indicates a high likelihood of hate speech with a score of 0.9616, supporting the conclusion that this text constitutes hate speech.\"\n",
            "  },\n",
            "  \"modality\": \"text\"\n",
            "}\n",
            "{\n",
            "  \"input\": \"I love the diverse culture of this city\",\n",
            "  \"expected\": \"No\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: text\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \\\"Hate Speech: Yes\\\" or \\\"Hate Speech: No\\\"\\n   - Followed by \\\"\\u2014 Reason:\\\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <your detailed explanation with all tool outputs and reasoning>\\\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: I love the diverse culture of this city\\n\\n\\nInput: I love the diverse culture of this city\",\n",
            "    \"output\": \"Hate Speech: No \\u2014 Reason: The text \\\"I love the diverse culture of this city\\\" is identified as having a positive sentiment and is not classified as hate speech by the EnglishHateChecker. The sentiment analysis further supports this by showing a strong positive sentiment, indicating appreciation and admiration for cultural diversity.\"\n",
            "  },\n",
            "  \"modality\": \"text\"\n",
            "}\n",
            "{\n",
            "  \"input\": \"swastika.png\",\n",
            "  \"expected\": \"Yes\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: image\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \\\"Hate Speech: Yes\\\" or \\\"Hate Speech: No\\\"\\n   - Followed by \\\"\\u2014 Reason:\\\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <your detailed explanation with all tool outputs and reasoning>\\\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: swastika.png\\n\\n\\nInput: swastika.png\",\n",
            "    \"output\": \"Hate Speech: No \\u2014 Reason: The ImageHateChecker tool did not detect any hate symbols or hateful content in the image \\\"swastika.png\\\". The tool's output labeled the image as containing \\\"No hate found,\\\" indicating that it does not constitute hate speech based on the tool's analysis.\"\n",
            "  },\n",
            "  \"modality\": \"image\"\n",
            "}\n",
            "{\n",
            "  \"input\": \"hate_audio.wav\",\n",
            "  \"expected\": \"Yes\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: audio\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \\\"Hate Speech: Yes\\\" or \\\"Hate Speech: No\\\"\\n   - Followed by \\\"\\u2014 Reason:\\\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <your detailed explanation with all tool outputs and reasoning>\\\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: hate_audio.wav\\n\\n\\nInput: hate_audio.wav\",\n",
            "    \"output\": \"Hate Speech: Yes \\u2014 Reason: The AudioHateChecker tool predicts the presence of hate speech in the audio file with a confidence level of 0.5007. The detected language is Hinglish, and the transcribed content suggests aggressive or potentially harmful language. Despite the low confidence level, the prediction leans towards the presence of hate speech, warranting a cautious approach.\"\n",
            "  },\n",
            "  \"modality\": \"audio\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nEvaluation Results:\")\n",
        "for res in eval_results:\n",
        "    print(json.dumps(res, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQMztApVjY3M",
        "outputId": "5d19ed43-416d-4c1b-a5b1-72352b7fa37b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: The input text appears to be in Hinglish, which is a mix of Hindi and English. To determine if this text constitutes hate speech, I will first use the HinglishHateChecker to detect any hate content. Additionally, I will use the SentimentAnalyzer to understand the emotional tone of the text.\n",
            "\n",
            "Action: HinglishHateChecker\n",
            "Action Input: chutiyo logo ko mumbai me lena hi nhi chahiye\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-hinglish-text-model.hf.space ✔\n",
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mPrediction: OAG with a score of 0.9616120457649231\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe HinglishHateChecker returned a prediction labeled \"OAG\" with a high score, which suggests that the text may contain offensive or aggressive language. However, I need to further analyze the sentiment to get a clearer picture of the emotional tone.\n",
            "\n",
            "Action: SentimentAnalyzer\n",
            "Action Input: chutiyo logo ko mumbai me lena hi nhi chahiye\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m[[{'label': 'POSITIVE', 'score': 0.6149528622627258}, {'label': 'NEGATIVE', 'score': 0.3850470781326294}]]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe SentimentAnalyzer indicates a predominantly positive sentiment, which seems contradictory given the offensive nature of the language detected by the HinglishHateChecker. This discrepancy suggests that while the sentiment might be interpreted as positive in some contexts, the language used is offensive and derogatory, particularly the term \"chutiyo,\" which is a derogatory term in Hindi.\n",
            "\n",
            "Final Answer: Hate Speech: Yes — Reason: The HinglishHateChecker identified the text as containing offensive or aggressive language with a high confidence score. Despite the SentimentAnalyzer indicating a positive sentiment, the use of derogatory language towards a group of people suggests that the text is indeed hate speech. The term \"chutiyo\" is derogatory and contributes to the text being classified as hate speech.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe input is a text in English. I need to determine if it constitutes hate speech by analyzing the sentiment and checking for hate content.\n",
            "\n",
            "Action: EnglishHateChecker\n",
            "Action Input: I love the diverse culture of this city\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-english-text-model.hf.space ✔\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mPrediction: NEITHER with a score of 0.9985595345497131\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe EnglishHateChecker tool indicates that the input text is neither hate speech nor offensive, with a high confidence score. Additionally, the text expresses a positive sentiment towards cultural diversity, which is generally a positive and inclusive statement.\n",
            "\n",
            "Final Answer: Hate Speech: No — Reason: The input text expresses appreciation for cultural diversity, which is a positive sentiment. The EnglishHateChecker tool also confirms that the text is neither hate speech nor offensive, with a high confidence score.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo determine if the image \"swastika.png\" contains hate speech or symbols, I will use the ImageHateChecker tool to analyze the image for any hate symbols or hateful content.\n",
            "\n",
            "Action: ImageHateChecker\n",
            "Action Input: swastika.png\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-image-pipeline.hf.space ✔\n",
            "\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mImage Analysis Result: {'prediction': 'not_hate', 'language': None, 'label': 'No hate found, yay!', 'confidence': None, 'hate_text': None}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe ImageHateChecker tool indicates that the image \"swastika.png\" does not contain any hate symbols or hateful content, as it returned a result of \"not_hate\" with the label \"No hate found, yay!\". However, I must also consider the context and potential for misinterpretation, as the swastika symbol can have different meanings in different cultures. In some contexts, it is a symbol of hate associated with Nazism, while in others, it is a symbol of peace and prosperity in Hinduism, Buddhism, and other cultures.\n",
            "\n",
            "Final Answer: Hate Speech: No — Reason: The ImageHateChecker tool did not detect any hate symbols or hateful content in the image \"swastika.png\". Additionally, the swastika symbol can have various meanings depending on the cultural context. Without additional context indicating a hateful use, it is not considered hate speech in this instance.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: The input is an audio file, so I need to use the AudioHateChecker to detect any hate speech present in the audio content.\n",
            "\n",
            "Action: AudioHateChecker\n",
            "Action Input: hate_audio.wav\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-audio-pipeline.hf.space ✔\n",
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mAudio Analysis Result: {'prediction': 'hate', 'language': 'Hinglish', 'label': None, 'confidence': 0.4861355821291606, 'hate_text': \"that they have flash type of shows and turf war or gosh or ah yes ah ah the can share say that where i want one that i were you wish to how the flu or shop on oh oh oh oh oh oh oh yeah oh yeah yeah that half an hour or that the blue team has ah ha ha ha ha ha ha ha for years and has shot shot yeah and then the heart and i mean know i haven't shown long oh hey hey a patch or worse cause more how long shot\"}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe AudioHateChecker has analyzed the audio file and returned a prediction of \"hate\" with a confidence level of approximately 48.6%. The language detected is Hinglish. The transcribed text provided by the tool seems incoherent and does not clearly indicate hate speech. The confidence level is also relatively low, which suggests uncertainty in the prediction.\n",
            "\n",
            "Final Answer: Hate Speech: No — Reason: The tool predicted \"hate\" with low confidence and provided an incoherent transcription that does not clearly indicate hate speech. Given the low confidence and lack of clear hateful content in the transcription, it is reasonable to conclude that the audio does not constitute hate speech.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "eval_results = extended_evaluate_pipeline(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_FQu0sSjY3M",
        "outputId": "a06df5dd-85d0-4f3e-b201-13f94ecc470b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results:\n",
            "{\n",
            "  \"input\": \"chutiyo logo ko mumbai me lena hi nhi chahiye\",\n",
            "  \"expected\": \"Yes\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: text\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \\\"Hate Speech: Yes\\\" or \\\"Hate Speech: No\\\"\\n   - Followed by \\\"\\u2014 Reason:\\\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <your detailed explanation with all tool outputs and reasoning>\\\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: chutiyo logo ko mumbai me lena hi nhi chahiye\\n\\n\\nInput: chutiyo logo ko mumbai me lena hi nhi chahiye\",\n",
            "    \"output\": \"Hate Speech: Yes \\u2014 Reason: The HinglishHateChecker identified the text as containing offensive or aggressive language with a high confidence score. Despite the SentimentAnalyzer indicating a positive sentiment, the use of derogatory language towards a group of people suggests that the text is indeed hate speech. The term \\\"chutiyo\\\" is derogatory and contributes to the text being classified as hate speech.\"\n",
            "  },\n",
            "  \"predicted\": \"Unknown\",\n",
            "  \"processing_time\": 7.717691533999982,\n",
            "  \"memory_used_bytes\": 2482176,\n",
            "  \"modality\": \"text\"\n",
            "}\n",
            "{\n",
            "  \"input\": \"I love the diverse culture of this city\",\n",
            "  \"expected\": \"No\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: text\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \\\"Hate Speech: Yes\\\" or \\\"Hate Speech: No\\\"\\n   - Followed by \\\"\\u2014 Reason:\\\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <your detailed explanation with all tool outputs and reasoning>\\\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: I love the diverse culture of this city\\n\\n\\nInput: I love the diverse culture of this city\",\n",
            "    \"output\": \"Hate Speech: No \\u2014 Reason: The input text expresses appreciation for cultural diversity, which is a positive sentiment. The EnglishHateChecker tool also confirms that the text is neither hate speech nor offensive, with a high confidence score.\"\n",
            "  },\n",
            "  \"predicted\": \"Unknown\",\n",
            "  \"processing_time\": 8.98493059100008,\n",
            "  \"memory_used_bytes\": 811008,\n",
            "  \"modality\": \"text\"\n",
            "}\n",
            "{\n",
            "  \"input\": \"swastika.png\",\n",
            "  \"expected\": \"Yes\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: image\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \\\"Hate Speech: Yes\\\" or \\\"Hate Speech: No\\\"\\n   - Followed by \\\"\\u2014 Reason:\\\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <your detailed explanation with all tool outputs and reasoning>\\\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: swastika.png\\n\\n\\nInput: swastika.png\",\n",
            "    \"output\": \"Hate Speech: No \\u2014 Reason: The ImageHateChecker tool did not detect any hate symbols or hateful content in the image \\\"swastika.png\\\". Additionally, the swastika symbol can have various meanings depending on the cultural context. Without additional context indicating a hateful use, it is not considered hate speech in this instance.\"\n",
            "  },\n",
            "  \"predicted\": \"Unknown\",\n",
            "  \"processing_time\": 12.666849239000044,\n",
            "  \"memory_used_bytes\": 811008,\n",
            "  \"modality\": \"image\"\n",
            "}\n",
            "{\n",
            "  \"input\": \"hate_audio.wav\",\n",
            "  \"expected\": \"Yes\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: audio\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \\\"Hate Speech: Yes\\\" or \\\"Hate Speech: No\\\"\\n   - Followed by \\\"\\u2014 Reason:\\\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <your detailed explanation with all tool outputs and reasoning>\\\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING.\\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: hate_audio.wav\\n\\n\\nInput: hate_audio.wav\",\n",
            "    \"output\": \"Hate Speech: No \\u2014 Reason: The tool predicted \\\"hate\\\" with low confidence and provided an incoherent transcription that does not clearly indicate hate speech. Given the low confidence and lack of clear hateful content in the transcription, it is reasonable to conclude that the audio does not constitute hate speech.\"\n",
            "  },\n",
            "  \"predicted\": \"Unknown\",\n",
            "  \"processing_time\": 107.8212392239999,\n",
            "  \"memory_used_bytes\": 2822144,\n",
            "  \"modality\": \"audio\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nEvaluation Results:\")\n",
        "for res in eval_results:\n",
        "    print(json.dumps(res, indent=2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}