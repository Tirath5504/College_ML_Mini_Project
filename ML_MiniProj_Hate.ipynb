{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-O-KTxkynd6N",
        "outputId": "33c83f84-5759-43ea-cc14-a282889655a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain langchain-community langchain-google-genai gradio_client python-dotenv langsmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jloG1RtZndBR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from gradio_client import Client, handle_file\n",
        "from langsmith import traceable\n",
        "from dotenv import load_dotenv\n",
        "from typing import Union, List, Dict, Any\n",
        "import json\n",
        "import mimetypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1df3_Z5ypRxX"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pwE2QEwTqJYI"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    max_retries=1,\n",
        "    api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2_p0JPSTqLmF"
      },
      "outputs": [],
      "source": [
        "@traceable\n",
        "def run_hinglish_hate_model(text: str) -> str:\n",
        "    try:\n",
        "        client = Client(\"dj-dawgs-ipd/IPD-Hinglish-Text-Model\")\n",
        "        label, score = client.predict(text, api_name=\"/predict\")\n",
        "        return f\"Prediction: {label} with a score of {score}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error calling Hinglish model: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "@traceable\n",
        "def run_english_hate_model(text: str) -> str:\n",
        "    try:\n",
        "        client = Client(\"dj-dawgs-ipd/IPD-Text-English-Finetune\")\n",
        "        label, score = client.predict(text, api_name=\"/predict\")\n",
        "        return f\"Prediction: {label} with a score of {score}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error calling English model: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "@traceable\n",
        "def run_image_hate_model(image_path: str) -> str:\n",
        "    try:\n",
        "        client = Client(\"dj-dawgs-ipd/IPD_IMAGE_PIPELINE\")\n",
        "        result = client.predict(handle_file(image_path), api_name=\"/predict\")\n",
        "        return f\"Image Analysis Result: {result}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error calling Image model: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "@traceable\n",
        "def run_audio_hate_model(audio_path: str) -> str:\n",
        "    try:\n",
        "        client = Client(\"dj-dawgs-ipd/IPD-Audio-Pipeline\")\n",
        "        result = client.predict(handle_file(audio_path), api_name=\"/predict\")\n",
        "        return f\"Audio Analysis Result: {result}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error calling Audio model: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "@traceable\n",
        "def run_sentiment_analysis(text: str) -> str:\n",
        "    try:\n",
        "        client = Client(\"cardiffnlp/twitter-roberta-base-sentiment-analysis\")\n",
        "        # The API is assumed to return a tuple: (sentiment_label, confidence_score)\n",
        "        sentiment, score = client.predict(text, api_name=\"/predict\")\n",
        "        return f\"Sentiment Analysis: {sentiment} with confidence {score}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error in Sentiment Analysis: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FRQvIl6MqNdF"
      },
      "outputs": [],
      "source": [
        "hinglish_tool = Tool.from_function(\n",
        "    func=run_hinglish_hate_model,\n",
        "    name=\"HinglishHateChecker\",\n",
        "    description=\"Detects hate speech in Hinglish text.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "english_tool = Tool.from_function(\n",
        "    func=run_english_hate_model,\n",
        "    name=\"EnglishHateChecker\",\n",
        "    description=\"Detects hate speech in English text.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_tool = Tool.from_function(\n",
        "    func=run_image_hate_model,\n",
        "    name=\"ImageHateChecker\",\n",
        "    description=\"Detects hate symbols or hateful content in images.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "audio_tool = Tool.from_function(\n",
        "    func=run_audio_hate_model,\n",
        "    name=\"AudioHateChecker\",\n",
        "    description=\"Detects hate speech in audio files.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentiment_tool = Tool.from_function(\n",
        "    func=run_sentiment_analysis,\n",
        "    name=\"SentimentAnalyzer\",\n",
        "    description=\"Analyzes the sentiment of text to assess emotional tone.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6oSum6RFqWqI"
      },
      "outputs": [],
      "source": [
        "tools = [hinglish_tool, english_tool, image_tool, audio_tool, sentiment_tool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_modality(input_data: Union[str, os.PathLike]) -> str:\n",
        "    if isinstance(input_data, str):\n",
        "        if os.path.exists(input_data):\n",
        "            mime_type, _ = mimetypes.guess_type(input_data)\n",
        "            if mime_type:\n",
        "                if mime_type.startswith(\"image\"):\n",
        "                    return \"image\"\n",
        "                elif mime_type.startswith(\"audio\"):\n",
        "                    return \"audio\"\n",
        "            return \"unknown\"\n",
        "        else:\n",
        "            # Assume text input\n",
        "            if any(word in input_data.lower() for word in [\"hai\", \"kya\", \"nahi\", \"chutiya\", \"bhen\"]):\n",
        "                return \"hinglish\"\n",
        "            else:\n",
        "                return \"english\"\n",
        "    return \"unknown\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cHXZKLYFqa5e"
      },
      "outputs": [],
      "source": [
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "@traceable\n",
        "def pipeline(input_data: Union[str, os.PathLike]):\n",
        "    modality = detect_modality(input_data)\n",
        "    system_instruction = f\"\"\"\n",
        "You are an AI agent that detects hate speech.\n",
        "Modality detected: {modality}\n",
        "Use the appropriate tool:\n",
        "- HinglishHateChecker for Hinglish\n",
        "- EnglishHateChecker for English\n",
        "- ImageHateChecker for image files\n",
        "- AudioHateChecker for audio files\n",
        "\n",
        "Full multimodal and multi-step pipeline:\n",
        "    1. Detects modality and (for text) language.\n",
        "    2. Calls external tools (hate detection, sentiment analysis, contextual lookup) as appropriate.\n",
        "    3. Constructs a detailed chain-of-thought prompt including all tool outputs.\n",
        "    4. Uses the Gemini LLM to consolidate and produce a final decision.\n",
        "\n",
        "You can use multiple tools if necessary and perform a chain of operations. \n",
        "Use your reasoning to decide which tools to use.\n",
        "\n",
        "Based on these tool outputs and your own reasoning, decide:\n",
        "- Is the input hate speech? (Answer Yes or No)\n",
        "- Provide a clear explanation integrating the tool outputs and any additional reasoning.\n",
        "\n",
        "Provide your answer in the format:\n",
        "\"Hate Speech: Yes/No — Reason: <tool output + your reasoning>\"\n",
        "\"\"\"\n",
        "\n",
        "    prompt = f\"{system_instruction}\\n\\nInput: {input_data}\"\n",
        "    return agent.invoke(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7UjUuLMnayr",
        "outputId": "38986502-b4ff-4055-f610-c8802f7b7b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe modality is audio, so I should use the AudioHateChecker to detect hate speech.\n",
            "Action: AudioHateChecker\n",
            "Action Input: hate_audio.wav\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-audio-pipeline.hf.space ✔\n",
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mAudio Analysis Result: {'prediction': 'hate', 'language': 'Hinglish', 'label': None, 'confidence': 0.4111775557200114, 'hate_text': \"that they have flash type of shows and turf war or gosh or ah yes ah ah the can share say that where i want one that i were you wish to how the flu or shop on oh oh oh oh oh oh oh yeah oh yeah yeah that half an hour or that the blue team has ah ha ha ha ha ha ha ha for years and has shot shot yeah and then the heart and i mean know i haven't shown long oh hey hey a patch or worse cause more how long shot\"}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe AudioHateChecker detected hate speech in the audio file. The extracted text contains potentially hateful phrases. Therefore, the input is hate speech.\n",
            "Final Answer: Hate Speech: Yes — Reason: The AudioHateChecker detected hate speech with a confidence of 0.4111775557200114. The extracted text contains phrases like \"turf war\" and other potentially hateful language.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': '\\nYou are an AI agent that detects hate speech.\\nModality detected: audio\\nUse the appropriate tool:\\n- HinglishHateChecker for Hinglish\\n- EnglishHateChecker for English\\n- ImageHateChecker for image files\\n- AudioHateChecker for audio files\\n\\nFull multimodal and multi-step pipeline:\\n    1. Detects modality and (for text) language.\\n    2. Calls external tools (hate detection, sentiment analysis, contextual lookup) as appropriate.\\n    3. Constructs a detailed chain-of-thought prompt including all tool outputs.\\n    4. Uses the Gemini LLM to consolidate and produce a final decision.\\n\\nYou can use multiple tools if necessary and perform a chain of operations. \\nUse your reasoning to decide which tools to use.\\n\\nBased on these tool outputs and your own reasoning, decide:\\n- Is the input hate speech? (Answer Yes or No)\\n- Provide a clear explanation integrating the tool outputs and any additional reasoning.\\n\\nProvide your answer in the format:\\n\"Hate Speech: Yes/No — Reason: <tool output + your reasoning>\"\\n\\n\\nInput: hate_audio.wav', 'output': 'Hate Speech: Yes — Reason: The AudioHateChecker detected hate speech with a confidence of 0.4111775557200114. The extracted text contains phrases like \"turf war\" and other potentially hateful language.'}\n"
          ]
        }
      ],
      "source": [
        "# print(pipeline(\"chutiyo logo ko mumbai me lena hi nhi chahiye\"))\n",
        "# print(pipeline(\"swastika.png\"))\n",
        "print(pipeline(\"hate_audio.wav\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "@traceable\n",
        "def evaluate_pipeline(test_dataset: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Evaluates the pipeline over a dataset of examples.\n",
        "    \n",
        "    Each dataset entry should be a dict with:\n",
        "      - 'input': The input data (text, file path, etc.)\n",
        "      - 'expected': The expected label (optional)\n",
        "    \n",
        "    Returns a list of results with input, expected, output, and (optionally) a score.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for example in test_dataset:\n",
        "        inp = example.get(\"input\")\n",
        "        expected = example.get(\"expected\", \"N/A\")\n",
        "        output = pipeline(inp)\n",
        "        result = {\n",
        "            \"input\": inp,\n",
        "            \"expected\": expected,\n",
        "            \"output\": output,\n",
        "            \"modality\": detect_modality(inp)\n",
        "        }\n",
        "        results.append(result)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dataset = [\n",
        "    {\"input\": \"chutiyo logo ko mumbai me lena hi nhi chahiye\", \"expected\": \"Yes\"},\n",
        "    {\"input\": \"I love the diverse culture of this city\", \"expected\": \"No\"},\n",
        "    # For file paths, replace with actual image/audio file paths:\n",
        "    {\"input\": \"swastika.png\", \"expected\": \"Yes\"},\n",
        "    {\"input\": \"hate_audio.wav\", \"expected\": \"Yes\"},\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe input is in Hinglish. I should use the HinglishHateChecker to detect hate speech.\n",
            "Action: HinglishHateChecker\n",
            "Action Input: chutiyo logo ko mumbai me lena hi nhi chahiye\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-hinglish-text-model.hf.space ✔\n",
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mPrediction: OAG with a score of 0.9616120457649231\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe HinglishHateChecker tool detected the input text as offensive, aggressive, or abusive (OAG) with a high score of 0.96. This indicates a high probability that the text contains hate speech or offensive content.\n",
            "\n",
            "Hate Speech: Yes — Reason: The HinglishHateChecker tool identified the text \"chutiyo logo ko mumbai me lena hi nhi chahiye\" as offensive, aggressive, or abusive with a score of 0.96, indicating a high likelihood of hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe HinglishHateChecker tool identified the text \"chutiyo logo ko mumbai me lena hi nhi chahiye\" as offensive, aggressive, or abusive with a score of 0.96, indicating a high likelihood of hate speech.\n",
            "Final Answer: Hate Speech: Yes — Reason: The HinglishHateChecker tool identified the text \"chutiyo logo ko mumbai me lena hi nhi chahiye\" as offensive, aggressive, or abusive with a score of 0.96, indicating a high likelihood of hate speech.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe input is in English, and I need to determine if it's hate speech. I should use the EnglishHateChecker to analyze the text.\n",
            "Action: EnglishHateChecker\n",
            "Action Input: I love the diverse culture of this city\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-english-text-model.hf.space ✔\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mPrediction: NEITHER with a score of 0.9985595345497131\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe EnglishHateChecker tool indicates that the input text is not hate speech. The sentiment expressed is positive and promotes inclusivity.\n",
            "\n",
            "Final Answer: Hate Speech: No — Reason: The EnglishHateChecker tool classified the input as NEITHER, with a high confidence score, indicating it is not hate speech. The text expresses positive sentiment towards cultural diversity.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe modality detected is image. I should use the ImageHateChecker to detect hate symbols or hateful content in the image.\n",
            "Action: ImageHateChecker\n",
            "Action Input: swastika.png\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-image-pipeline.hf.space ✔\n",
            "\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mImage Analysis Result: {'prediction': 'not_hate', 'language': None, 'label': 'No hate found, yay!', 'confidence': None, 'hate_text': None}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe ImageHateChecker tool has analyzed the image and found no hate symbols or hateful content.\n",
            "\n",
            "Final Answer: Hate Speech: No — Reason: The ImageHateChecker tool found no hate symbols or hateful content in the image.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe modality is audio, so I should use the AudioHateChecker to detect hate speech in the audio file.\n",
            "Action: AudioHateChecker\n",
            "Action Input: hate_audio.wav\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-audio-pipeline.hf.space ✔\n",
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mAudio Analysis Result: {'prediction': 'hate', 'language': 'Hinglish', 'label': None, 'confidence': 0.39118879040082294, 'hate_text': \"that they have a flash type of shows can share turf war or gosh or ah yes have ah and you can share say that where i want one that i were you wish to how the flu or shop on oh oh oh oh oh oh oh yeah oh yeah yeah that half an hour or that the blue team has ah ha ha ha ha ha ha ha for an edge of the and has shot shot yeah and then how long i mean i know i haven't shown long oh hey hey a patch or worse cause more how long shot on\"}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The AudioHateChecker detected hate speech in the audio file. The tool's prediction is 'hate' with a confidence of 0.39118879040082294. The language identified is Hinglish. The extracted hate text includes phrases that suggest conflict and aggression, indicating potential hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The AudioHateChecker detected hate speech in the audio file. The tool's prediction is 'hate' with a confidence of 0.39118879040082294. The language identified is Hinglish. The extracted hate text includes phrases that suggest conflict and aggression (\"turf war,\" \"shot shot,\" \"edge of the\"), indicating potential hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The AudioHateChecker detected hate speech in the audio file. The tool's prediction is 'hate' with a confidence of 0.39118879040082294. The language identified is Hinglish. The extracted hate text includes phrases that suggest conflict and aggression (\"turf war,\" \"shot shot,\" \"edge of the\"), indicating potential hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The AudioHateChecker detected hate speech in the audio file. The tool's prediction is 'hate' with a confidence of 0.39118879040082294. The language identified is Hinglish. The extracted hate text includes phrases that suggest conflict and aggression (\"turf war,\" \"shot shot,\" \"edge of the\"), indicating potential hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The AudioHateChecker detected hate speech in the audio file. The tool's prediction is 'hate' with a confidence of 0.39118879040082294. The language identified is Hinglish. The extracted hate text includes phrases that suggest conflict and aggression (\"turf war,\" \"shot shot,\" \"edge of the\"), indicating potential hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The AudioHateChecker detected hate speech in the audio file. The tool's prediction is 'hate' with a confidence of 0.39118879040082294. The language identified is Hinglish. The extracted hate text includes phrases that suggest conflict and aggression (\"turf war,\" \"shot shot,\" \"edge of the\"), indicating potential hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The AudioHateChecker detected hate speech in the audio file. The tool's prediction is 'hate' with a confidence of 0.39118879040082294. The language identified is Hinglish. The extracted hate text includes phrases that suggest conflict and aggression (\"turf war,\" \"shot shot,\" \"edge of the\"), indicating potential hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The AudioHateChecker detected hate speech in the audio file. The tool's prediction is 'hate' with a confidence of 0.39118879040082294. The language identified is Hinglish. The extracted hate text includes phrases that suggest conflict and aggression (\"turf war,\" \"shot shot,\" \"edge of the\"), indicating potential hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The AudioHateChecker detected hate speech in the audio file. The tool's prediction is 'hate' with a confidence of 0.39118879040082294. The language identified is Hinglish. The extracted hate text includes phrases that suggest conflict and aggression (\"turf war,\" \"shot shot,\" \"edge of the\"), indicating potential hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The AudioHateChecker detected hate speech in the audio file. The tool's prediction is 'hate' with a confidence of 0.39118879040082294. The language identified is Hinglish. The extracted hate text includes phrases that suggest conflict and aggression (\"turf war,\" \"shot shot,\" \"edge of the\"), indicating potential hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The AudioHateChecker detected hate speech in the audio file. The tool's prediction is 'hate' with a confidence of 0.39118879040082294. The language identified is Hinglish. The extracted hate text includes phrases that suggest conflict and aggression (\"turf war,\" \"shot shot,\" \"edge of the\"), indicating potential hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The AudioHateChecker detected hate speech in the audio file. The tool's prediction is 'hate' with a confidence of 0.39118879040082294. The language identified is Hinglish. The extracted hate text includes phrases that suggest conflict and aggression (\"turf war,\" \"shot shot,\" \"edge of the\"), indicating potential hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The AudioHateChecker detected hate speech in the audio file. The tool's prediction is 'hate' with a confidence of 0.39118879040082294. The language identified is Hinglish. The extracted hate text includes phrases that suggest conflict and aggression (\"turf war,\" \"shot shot,\" \"edge of the\"), indicating potential hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The AudioHateChecker detected hate speech in the audio file. The tool's prediction is 'hate' with a confidence of 0.39118879040082294. The language identified is Hinglish. The extracted hate text includes phrases that suggest conflict and aggression (\"turf war,\" \"shot shot,\" \"edge of the\"), indicating potential hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "eval_results = evaluate_pipeline(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation Results:\n",
            "{\n",
            "  \"input\": \"chutiyo logo ko mumbai me lena hi nhi chahiye\",\n",
            "  \"expected\": \"Yes\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an AI agent that detects hate speech.\\nModality detected: english\\nUse the appropriate tool:\\n- HinglishHateChecker for Hinglish\\n- EnglishHateChecker for English\\n- ImageHateChecker for image files\\n- AudioHateChecker for audio files\\n\\nFull multimodal and multi-step pipeline:\\n    1. Detects modality and (for text) language.\\n    2. Calls external tools (hate detection, sentiment analysis, contextual lookup) as appropriate.\\n    3. Constructs a detailed chain-of-thought prompt including all tool outputs.\\n    4. Uses the Gemini LLM to consolidate and produce a final decision.\\n\\nYou can use multiple tools if necessary and perform a chain of operations. \\nUse your reasoning to decide which tools to use.\\n\\nBased on these tool outputs and your own reasoning, decide:\\n- Is the input hate speech? (Answer Yes or No)\\n- Provide a clear explanation integrating the tool outputs and any additional reasoning.\\n\\nProvide your answer in the format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <tool output + your reasoning>\\\"\\n\\n\\nInput: chutiyo logo ko mumbai me lena hi nhi chahiye\",\n",
            "    \"output\": \"Hate Speech: Yes \\u2014 Reason: The HinglishHateChecker tool identified the text \\\"chutiyo logo ko mumbai me lena hi nhi chahiye\\\" as offensive, aggressive, or abusive with a score of 0.96, indicating a high likelihood of hate speech.\"\n",
            "  },\n",
            "  \"modality\": \"english\"\n",
            "}\n",
            "{\n",
            "  \"input\": \"I love the diverse culture of this city\",\n",
            "  \"expected\": \"No\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an AI agent that detects hate speech.\\nModality detected: english\\nUse the appropriate tool:\\n- HinglishHateChecker for Hinglish\\n- EnglishHateChecker for English\\n- ImageHateChecker for image files\\n- AudioHateChecker for audio files\\n\\nFull multimodal and multi-step pipeline:\\n    1. Detects modality and (for text) language.\\n    2. Calls external tools (hate detection, sentiment analysis, contextual lookup) as appropriate.\\n    3. Constructs a detailed chain-of-thought prompt including all tool outputs.\\n    4. Uses the Gemini LLM to consolidate and produce a final decision.\\n\\nYou can use multiple tools if necessary and perform a chain of operations. \\nUse your reasoning to decide which tools to use.\\n\\nBased on these tool outputs and your own reasoning, decide:\\n- Is the input hate speech? (Answer Yes or No)\\n- Provide a clear explanation integrating the tool outputs and any additional reasoning.\\n\\nProvide your answer in the format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <tool output + your reasoning>\\\"\\n\\n\\nInput: I love the diverse culture of this city\",\n",
            "    \"output\": \"Hate Speech: No \\u2014 Reason: The EnglishHateChecker tool classified the input as NEITHER, with a high confidence score, indicating it is not hate speech. The text expresses positive sentiment towards cultural diversity.\"\n",
            "  },\n",
            "  \"modality\": \"english\"\n",
            "}\n",
            "{\n",
            "  \"input\": \"swastika.png\",\n",
            "  \"expected\": \"Yes\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an AI agent that detects hate speech.\\nModality detected: image\\nUse the appropriate tool:\\n- HinglishHateChecker for Hinglish\\n- EnglishHateChecker for English\\n- ImageHateChecker for image files\\n- AudioHateChecker for audio files\\n\\nFull multimodal and multi-step pipeline:\\n    1. Detects modality and (for text) language.\\n    2. Calls external tools (hate detection, sentiment analysis, contextual lookup) as appropriate.\\n    3. Constructs a detailed chain-of-thought prompt including all tool outputs.\\n    4. Uses the Gemini LLM to consolidate and produce a final decision.\\n\\nYou can use multiple tools if necessary and perform a chain of operations. \\nUse your reasoning to decide which tools to use.\\n\\nBased on these tool outputs and your own reasoning, decide:\\n- Is the input hate speech? (Answer Yes or No)\\n- Provide a clear explanation integrating the tool outputs and any additional reasoning.\\n\\nProvide your answer in the format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <tool output + your reasoning>\\\"\\n\\n\\nInput: swastika.png\",\n",
            "    \"output\": \"Hate Speech: No \\u2014 Reason: The ImageHateChecker tool found no hate symbols or hateful content in the image.\"\n",
            "  },\n",
            "  \"modality\": \"image\"\n",
            "}\n",
            "{\n",
            "  \"input\": \"hate_audio.wav\",\n",
            "  \"expected\": \"Yes\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an AI agent that detects hate speech.\\nModality detected: audio\\nUse the appropriate tool:\\n- HinglishHateChecker for Hinglish\\n- EnglishHateChecker for English\\n- ImageHateChecker for image files\\n- AudioHateChecker for audio files\\n\\nFull multimodal and multi-step pipeline:\\n    1. Detects modality and (for text) language.\\n    2. Calls external tools (hate detection, sentiment analysis, contextual lookup) as appropriate.\\n    3. Constructs a detailed chain-of-thought prompt including all tool outputs.\\n    4. Uses the Gemini LLM to consolidate and produce a final decision.\\n\\nYou can use multiple tools if necessary and perform a chain of operations. \\nUse your reasoning to decide which tools to use.\\n\\nBased on these tool outputs and your own reasoning, decide:\\n- Is the input hate speech? (Answer Yes or No)\\n- Provide a clear explanation integrating the tool outputs and any additional reasoning.\\n\\nProvide your answer in the format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <tool output + your reasoning>\\\"\\n\\n\\nInput: hate_audio.wav\",\n",
            "    \"output\": \"Agent stopped due to iteration limit or time limit.\"\n",
            "  },\n",
            "  \"modality\": \"audio\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nEvaluation Results:\")\n",
        "for res in eval_results:\n",
        "    print(json.dumps(res, indent=2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
