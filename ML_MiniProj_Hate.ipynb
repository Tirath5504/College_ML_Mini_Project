{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-O-KTxkynd6N",
        "outputId": "33c83f84-5759-43ea-cc14-a282889655a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain langchain-community langchain-google-genai gradio_client python-dotenv langsmith transformers torch tensorflow tf_keras scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jloG1RtZndBR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from gradio_client import Client, handle_file\n",
        "from langsmith import traceable\n",
        "from dotenv import load_dotenv\n",
        "from typing import Union, List, Dict, Any\n",
        "import json\n",
        "import mimetypes\n",
        "import logging\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1df3_Z5ypRxX"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "logging.basicConfig(level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"gemini-2.0-flash\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "classifier = pipeline(\"text-classification\", model=model_id, top_k=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pwE2QEwTqJYI"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=LLM_MODEL,\n",
        "    max_retries=1,\n",
        "    api_key=API_KEY\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_client(client_id: str) -> Client:\n",
        "    return Client(client_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "@traceable\n",
        "def run_text_model(text: str, client_id: str) -> str:\n",
        "    try:\n",
        "        client = create_client(client_id)\n",
        "        label, score = client.predict(text, api_name=\"/predict\")\n",
        "        return f\"Prediction: {label} with a score of {score}\"\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in text model {client_id}: {e}\")\n",
        "        return f\"Error: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "@traceable\n",
        "def run_hinglish_hate_model(text: str) -> str:\n",
        "    return run_text_model(text, \"dj-dawgs-ipd/IPD-Hinglish-Text-Model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "@traceable\n",
        "def run_english_hate_model(text: str) -> str:\n",
        "    return run_text_model(text, \"dj-dawgs-ipd/IPD-Text-English-Finetune\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "@traceable\n",
        "def run_image_hate_model(image_path: str) -> str:\n",
        "    try:\n",
        "        client = Client(\"dj-dawgs-ipd/IPD_IMAGE_PIPELINE\")\n",
        "        result = client.predict(handle_file(image_path), api_name=\"/predict\")\n",
        "        return f\"Image Analysis Result: {result}\"\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in image model: {e}\")\n",
        "        return f\"Error calling Image model: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "@traceable\n",
        "def run_audio_hate_model(audio_path: str) -> str:\n",
        "    try:\n",
        "        client = Client(\"dj-dawgs-ipd/IPD-Audio-Pipeline\")\n",
        "        result = client.predict(handle_file(audio_path), api_name=\"/predict\")\n",
        "        return f\"Audio Analysis Result: {result}\"\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in audio model: {e}\")\n",
        "        return f\"Error calling Audio model: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "@traceable\n",
        "def run_sentiment_analysis(text: str) -> str:\n",
        "    try:\n",
        "        prediction = classifier(text)\n",
        "        return prediction\n",
        "        # client = Client(\"https://ck42-sentiment-model-comparison.hf.space/--replicas/ftdum/\")\n",
        "        # sentiment_data = client.predict(text, api_name=\"/predict_2\")\n",
        "        # if isinstance(sentiment_data, list) and all(isinstance(item, (list, tuple)) for item in sentiment_data):\n",
        "        #     formatted_sentiments = \", \".join(\n",
        "        #         [f\"{sentiment} ({score:.2f})\" for sentiment, score in sentiment_data]\n",
        "        #     )\n",
        "        # else:\n",
        "        #     formatted_sentiments = str(sentiment_data)\n",
        "        # return f\"Sentiment Analysis: {formatted_sentiments}\"\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in sentiment analysis: {e}\")\n",
        "        return f\"Error: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FRQvIl6MqNdF"
      },
      "outputs": [],
      "source": [
        "hinglish_tool = Tool.from_function(\n",
        "    func=run_hinglish_hate_model,\n",
        "    name=\"HinglishHateChecker\",\n",
        "    description=\"Detects hate speech in Hinglish text.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "english_tool = Tool.from_function(\n",
        "    func=run_english_hate_model,\n",
        "    name=\"EnglishHateChecker\",\n",
        "    description=\"Detects hate speech in English text.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_tool = Tool.from_function(\n",
        "    func=run_image_hate_model,\n",
        "    name=\"ImageHateChecker\",\n",
        "    description=\"Detects hate symbols or hateful content in images.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "audio_tool = Tool.from_function(\n",
        "    func=run_audio_hate_model,\n",
        "    name=\"AudioHateChecker\",\n",
        "    description=\"Detects hate speech in audio files.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentiment_tool = Tool.from_function(\n",
        "    func=run_sentiment_analysis,\n",
        "    name=\"SentimentAnalyzer\",\n",
        "    description=\"Analyzes the sentiment of text to assess emotional tone.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6oSum6RFqWqI"
      },
      "outputs": [],
      "source": [
        "tools = [hinglish_tool, english_tool, image_tool, audio_tool, sentiment_tool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_modality(input_data: Union[str, os.PathLike]) -> str:\n",
        "    if isinstance(input_data, str):\n",
        "        if os.path.exists(input_data):\n",
        "            mime_type, _ = mimetypes.guess_type(input_data)\n",
        "            if mime_type:\n",
        "                if mime_type.startswith(\"image\"):\n",
        "                    return \"image\"\n",
        "                elif mime_type.startswith(\"audio\"):\n",
        "                    return \"audio\"\n",
        "            return \"unknown\"\n",
        "        else:\n",
        "            return \"text\"\n",
        "    return \"unknown\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "cHXZKLYFqa5e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\TIRATH BHATHAWALA\\AppData\\Local\\Temp\\ipykernel_21616\\4274493085.py:1: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ],
      "source": [
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "@traceable\n",
        "def pipeline(input_data: Union[str, os.PathLike]):\n",
        "    modality = detect_modality(input_data)\n",
        "    system_instruction = f\"\"\"\n",
        "You are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\n",
        "\n",
        "Modality Detected: {modality}\n",
        "\n",
        "Use the following tools as applicable:\n",
        "- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\n",
        "- For image files: use the ImageHateChecker.\n",
        "- For audio files: use the AudioHateChecker.\n",
        "\n",
        "Instructions:\n",
        "1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\n",
        "2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \n",
        "4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\n",
        "   - \"Hate Speech: Yes\" or \"Hate Speech: No\"\n",
        "   - Followed by \"— Reason:\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\n",
        "\n",
        "Final Output Format:\n",
        "\"Hate Speech: Yes/No — Reason: <your detailed explanation with all tool outputs and reasoning>\"\n",
        "\n",
        "IMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \n",
        "SOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\n",
        "\n",
        "Now, process the following input:\n",
        "Input: {input_data}\n",
        "\"\"\"\n",
        "    prompt = f\"{system_instruction}\\n\\nInput: {input_data}\"\n",
        "    return agent.invoke(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7UjUuLMnayr",
        "outputId": "38986502-b4ff-4055-f610-c8802f7b7b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe input is an image file named \"swastika.png\". I should use the ImageHateChecker to analyze it.\n",
            "Action: ImageHateChecker\n",
            "Action Input: swastika.png\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-image-pipeline.hf.space ✔\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-image-pipeline.hf.space/config \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-image-pipeline.hf.space/info?serialize=False \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-image-pipeline.hf.space/heartbeat/8d23a525-b565-49fa-8260-958424dee1d9 \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://dj-dawgs-ipd-ipd-image-pipeline.hf.space/upload \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://dj-dawgs-ipd-ipd-image-pipeline.hf.space/queue/join \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-image-pipeline.hf.space/queue/data?session_hash=8d23a525-b565-49fa-8260-958424dee1d9 \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mImage Analysis Result: {'prediction': 'not_hate', 'language': None, 'label': 'No hate found, yay!', 'confidence': None, 'hate_text': None}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe ImageHateChecker found no hate in the image. However, the swastika is a symbol that is often associated with hate groups. Given its strong association with Nazi Germany and white supremacist ideologies, its presence can reasonably be interpreted as hate speech, even if the tool does not recognize it as such.\n",
            "\n",
            "Hate Speech: Yes — Reason: While the ImageHateChecker did not detect hate speech, the image contains a swastika, a symbol strongly associated with hate groups, particularly Nazi Germany, and ideologies of racial supremacy. Therefore, the presence of this symbol constitutes hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Hate Speech: Yes — Reason: While the ImageHateChecker did not detect hate speech, the image contains a swastika, a symbol strongly associated with hate groups, particularly Nazi Germany, and ideologies of racial supremacy. Therefore, the presence of this symbol constitutes hate speech.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': '\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: image\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \"Hate Speech: Yes\" or \"Hate Speech: No\"\\n   - Followed by \"— Reason:\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\"Hate Speech: Yes/No — Reason: <your detailed explanation with all tool outputs and reasoning>\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: swastika.png\\n\\n\\nInput: swastika.png', 'output': 'Hate Speech: Yes — Reason: While the ImageHateChecker did not detect hate speech, the image contains a swastika, a symbol strongly associated with hate groups, particularly Nazi Germany, and ideologies of racial supremacy. Therefore, the presence of this symbol constitutes hate speech.'}\n"
          ]
        }
      ],
      "source": [
        "# print(pipeline(\"chutiyo logo ko mumbai me lena hi nhi chahiye\"))\n",
        "print(pipeline(\"swastika.png\"))\n",
        "# print(pipeline(\"hate_audio.wav\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "@traceable\n",
        "def evaluate_pipeline(test_dataset: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "    results = []\n",
        "    for example in test_dataset:\n",
        "        inp = example.get(\"input\")\n",
        "        expected = example.get(\"expected\", \"N/A\")\n",
        "        output = pipeline(inp)\n",
        "        result = {\n",
        "            \"input\": inp,\n",
        "            \"expected\": expected,\n",
        "            \"output\": output,\n",
        "            \"modality\": detect_modality(inp)\n",
        "        }\n",
        "        results.append(result)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "import psutil\n",
        "import time\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "def extended_evaluate_pipeline(test_dataset: List[Dict[str, Any]], compute_metrics: bool = True):\n",
        "    results = []\n",
        "    predictions = []\n",
        "    ground_truths = []\n",
        "    \n",
        "    for example in test_dataset:\n",
        "        inp = example.get(\"input\")\n",
        "        expected = example.get(\"expected\")  # e.g., \"Yes\" or \"No\"\n",
        "        \n",
        "        process = psutil.Process(os.getpid())\n",
        "        mem_before = process.memory_info().rss\n",
        "        \n",
        "        start_time = time.perf_counter()\n",
        "        output = pipeline(inp)\n",
        "        end_time = time.perf_counter()\n",
        "        processing_time = end_time - start_time\n",
        "        \n",
        "        mem_after = process.memory_info().rss\n",
        "        mem_used = mem_after - mem_before\n",
        "\n",
        "        # Assume output follows: \"Hate Speech: Yes — Reason: <...>\"\n",
        "        predicted = \"Unknown\"\n",
        "        if \"Hate Speech:\" in output:\n",
        "            try:\n",
        "                predicted = output.split(\"Hate Speech:\")[1].split(\"—\")[0].strip()\n",
        "            except Exception:\n",
        "                predicted = output.split(\"Hate Speech:\")[1].strip()\n",
        "        \n",
        "        result = {\n",
        "            \"input\": inp,\n",
        "            \"expected\": expected,\n",
        "            \"output\": output,\n",
        "            \"predicted\": predicted,\n",
        "            \"processing_time\": processing_time,\n",
        "            \"memory_used_bytes\": mem_used,\n",
        "            \"modality\": detect_modality(inp)\n",
        "        }\n",
        "        results.append(result)\n",
        "        \n",
        "        if expected is not None:\n",
        "            ground_truths.append(expected)\n",
        "            predictions.append(predicted)\n",
        "    \n",
        "    if compute_metrics and ground_truths:\n",
        "        try:\n",
        "            # Assuming binary classification where positive label is \"Yes\"\n",
        "            precision = precision_score(ground_truths, predictions, pos_label=\"Yes\", average=\"binary\")\n",
        "            recall = recall_score(ground_truths, predictions, pos_label=\"Yes\", average=\"binary\")\n",
        "            f1 = f1_score(ground_truths, predictions, pos_label=\"Yes\", average=\"binary\")\n",
        "            conf_matrix = confusion_matrix(ground_truths, predictions, labels=[\"Yes\", \"No\"])\n",
        "            metrics = {\n",
        "                \"precision\": precision,\n",
        "                \"recall\": recall,\n",
        "                \"f1_score\": f1,\n",
        "                \"confusion_matrix\": conf_matrix.tolist()\n",
        "            }\n",
        "        except Exception as e:\n",
        "            metrics = {\"error\": f\"Could not compute metrics: {str(e)}\"}\n",
        "        \n",
        "        return results, metrics\n",
        "    else:\n",
        "        return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dataset = [\n",
        "    {\"input\": \"chutiyo logo ko mumbai me lena hi nhi chahiye\", \"expected\": \"Yes\"},\n",
        "    {\"input\": \"I love the diverse culture of this city\", \"expected\": \"No\"},\n",
        "    {\"input\": \"swastika.png\", \"expected\": \"Yes\"},\n",
        "    {\"input\": \"hate_audio.wav\", \"expected\": \"Yes\"},\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe input is text and appears to be in Hinglish. I should use the HinglishHateChecker to detect hate speech and the SentimentAnalyzer to analyze the sentiment.\n",
            "Action: HinglishHateChecker\n",
            "Action Input: chutiyo logo ko mumbai me lena hi nhi chahiye\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-hinglish-text-model.hf.space ✔\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-hinglish-text-model.hf.space/config \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-hinglish-text-model.hf.space/info?serialize=False \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-hinglish-text-model.hf.space/heartbeat/966c5736-0e1f-40a6-a022-32c425b81595 \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://dj-dawgs-ipd-ipd-hinglish-text-model.hf.space/queue/join \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-hinglish-text-model.hf.space/queue/data?session_hash=966c5736-0e1f-40a6-a022-32c425b81595 \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mPrediction: OAG with a score of 0.9616120457649231\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe HinglishHateChecker has flagged the input as offensive, with a high score of 0.96. This indicates a high probability of hate speech. I will now use the SentimentAnalyzer to understand the emotional tone.\n",
            "Action: SentimentAnalyzer\n",
            "Action Input: chutiyo logo ko mumbai me lena hi nhi chahiye\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m[[{'label': 'POSITIVE', 'score': 0.6149532794952393}, {'label': 'NEGATIVE', 'score': 0.38504672050476074}]]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe SentimentAnalyzer indicates a slightly positive sentiment. However, the HinglishHateChecker strongly suggests the presence of offensive language. Considering the derogatory nature of the words used, I conclude that this input constitutes hate speech despite the SentimentAnalyzer.\n",
            "\n",
            "Final Answer: Hate Speech: Yes — Reason: The HinglishHateChecker flagged the input as offensive with a high score of 0.96, indicating a high probability of hate speech. While the sentiment analysis indicates a slightly positive sentiment, the derogatory nature of the words used outweighs this, leading to the conclusion that the input constitutes hate speech.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe input is text and appears to be in English. I will use the EnglishHateChecker to detect hate speech and the SentimentAnalyzer to analyze the sentiment.\n",
            "Action: EnglishHateChecker\n",
            "Action Input: I love the diverse culture of this city\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-english-text-model.hf.space ✔\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-english-text-model.hf.space/config \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-english-text-model.hf.space/info?serialize=False \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-english-text-model.hf.space/heartbeat/fee73953-ecee-4193-a7b5-60f83fbdd0e8 \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://dj-dawgs-ipd-ipd-english-text-model.hf.space/queue/join \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-english-text-model.hf.space/queue/data?session_hash=fee73953-ecee-4193-a7b5-60f83fbdd0e8 \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mPrediction: NEITHER with a score of 0.9985595345497131\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe EnglishHateChecker indicates that the text is neither hateful nor offensive. I will now use the SentimentAnalyzer to analyze the sentiment of the text.\n",
            "Action: SentimentAnalyzer\n",
            "Action Input: I love the diverse culture of this city\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m[[{'label': 'POSITIVE', 'score': 0.9998651742935181}, {'label': 'NEGATIVE', 'score': 0.00013480843335855752}]]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe SentimentAnalyzer indicates a highly positive sentiment. Therefore, based on the EnglishHateChecker and SentimentAnalyzer, the input does not constitute hate speech.\n",
            "Final Answer: Hate Speech: No — Reason: The EnglishHateChecker classified the input as NEITHER with a high confidence score, and the SentimentAnalyzer detected a highly positive sentiment. This suggests that the input does not contain hate speech.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe input is an image file named \"swastika.png\". I should use the ImageHateChecker to analyze it.\n",
            "Action: ImageHateChecker\n",
            "Action Input: swastika.png\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-image-pipeline.hf.space ✔\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-image-pipeline.hf.space/config \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-image-pipeline.hf.space/info?serialize=False \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-image-pipeline.hf.space/heartbeat/32bd0d0e-4f60-4bcd-a82c-26ea8a50108b \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://dj-dawgs-ipd-ipd-image-pipeline.hf.space/upload \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://dj-dawgs-ipd-ipd-image-pipeline.hf.space/queue/join \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-image-pipeline.hf.space/queue/data?session_hash=32bd0d0e-4f60-4bcd-a82c-26ea8a50108b \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mImage Analysis Result: {'prediction': 'not_hate', 'language': None, 'label': 'No hate found, yay!', 'confidence': None, 'hate_text': None}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe ImageHateChecker found no hate in the image. However, the swastika is a symbol that is often associated with hate, particularly Nazi Germany. While the swastika itself is an ancient religious symbol, its appropriation by the Nazi regime has made it a symbol of hate in many contexts. Therefore, even though the tool says that no hate was found, I must consider the historical and social context of the symbol. Given the potential for the swastika to be interpreted as a symbol of hate, especially when displayed without context, I will classify this as hate speech.\n",
            "\n",
            "Final Answer: Hate Speech: Yes — Reason: The image contains a swastika, a symbol historically associated with Nazi Germany and hate, despite the tool classifying it as not hate. The context and potential for misinterpretation necessitate classifying it as hate speech.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe input is an audio file. I should use the AudioHateChecker to detect hate speech.\n",
            "Action: AudioHateChecker\n",
            "Action Input: hate_audio.wav\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-audio-pipeline.hf.space ✔\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-audio-pipeline.hf.space/config \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-audio-pipeline.hf.space/gradio_api/info?serialize=False \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-audio-pipeline.hf.space/gradio_api/heartbeat/8f15802c-5122-481c-b954-c85fd8a026f7 \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://dj-dawgs-ipd-ipd-audio-pipeline.hf.space/gradio_api/upload \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://dj-dawgs-ipd-ipd-audio-pipeline.hf.space/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-audio-pipeline.hf.space/gradio_api/queue/data?session_hash=8f15802c-5122-481c-b954-c85fd8a026f7 \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mAudio Analysis Result: {'prediction': 'hate', 'language': 'Hinglish', 'label': None, 'confidence': 0.3586863974730174, 'hate_text': \"that they have a flash type of shows can share turf war or gosh or ah yes have ah and you can share say that where i want one that i were you wish to how the flu or shop on oh oh oh oh oh oh oh yeah oh yeah yeah that half an hour or that the blue team has ah ha ha ha ha ha ha ha for an edge of the and has shot shot yeah and then how long i mean i know i haven't shown long oh hey hey a patch or worse cause more how long shot on\"}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe AudioHateChecker has detected hate speech in the audio file. The prediction is 'hate' with a confidence of 0.3586863974730174. The language detected is Hinglish. The 'hate_text' provided contains potentially hateful phrases and terms, although the low confidence score suggests it is not definitive. Given the tool's output indicating hate speech and the presence of potentially offensive language, I will classify this as hate speech.\n",
            "\n",
            "Hate Speech: Yes — Reason: The AudioHateChecker detected hate speech in the audio file \"hate_audio.wav\" with a confidence of 0.3586863974730174. The tool identified potentially hateful phrases.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The AudioHateChecker detected hate speech in the audio file \"hate_audio.wav\" with a confidence of 0.3586863974730174. The tool identified potentially hateful phrases.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Hate Speech: Yes — Reason: The AudioHateChecker detected hate speech in the audio file \"hate_audio.wav\" with a confidence of 0.3586863974730174. The tool identified potentially hateful phrases.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "eval_results = evaluate_pipeline(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation Results:\n",
            "{\n",
            "  \"input\": \"chutiyo logo ko mumbai me lena hi nhi chahiye\",\n",
            "  \"expected\": \"Yes\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: text\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \\\"Hate Speech: Yes\\\" or \\\"Hate Speech: No\\\"\\n   - Followed by \\\"\\u2014 Reason:\\\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <your detailed explanation with all tool outputs and reasoning>\\\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: chutiyo logo ko mumbai me lena hi nhi chahiye\\n\\n\\nInput: chutiyo logo ko mumbai me lena hi nhi chahiye\",\n",
            "    \"output\": \"Hate Speech: Yes \\u2014 Reason: The HinglishHateChecker flagged the input as offensive with a high score of 0.96, indicating a high probability of hate speech. While the sentiment analysis indicates a slightly positive sentiment, the derogatory nature of the words used outweighs this, leading to the conclusion that the input constitutes hate speech.\"\n",
            "  },\n",
            "  \"modality\": \"text\"\n",
            "}\n",
            "{\n",
            "  \"input\": \"I love the diverse culture of this city\",\n",
            "  \"expected\": \"No\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: text\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \\\"Hate Speech: Yes\\\" or \\\"Hate Speech: No\\\"\\n   - Followed by \\\"\\u2014 Reason:\\\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <your detailed explanation with all tool outputs and reasoning>\\\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: I love the diverse culture of this city\\n\\n\\nInput: I love the diverse culture of this city\",\n",
            "    \"output\": \"Hate Speech: No \\u2014 Reason: The EnglishHateChecker classified the input as NEITHER with a high confidence score, and the SentimentAnalyzer detected a highly positive sentiment. This suggests that the input does not contain hate speech.\"\n",
            "  },\n",
            "  \"modality\": \"text\"\n",
            "}\n",
            "{\n",
            "  \"input\": \"swastika.png\",\n",
            "  \"expected\": \"Yes\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: image\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \\\"Hate Speech: Yes\\\" or \\\"Hate Speech: No\\\"\\n   - Followed by \\\"\\u2014 Reason:\\\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <your detailed explanation with all tool outputs and reasoning>\\\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: swastika.png\\n\\n\\nInput: swastika.png\",\n",
            "    \"output\": \"Hate Speech: Yes \\u2014 Reason: The image contains a swastika, a symbol historically associated with Nazi Germany and hate, despite the tool classifying it as not hate. The context and potential for misinterpretation necessitate classifying it as hate speech.\"\n",
            "  },\n",
            "  \"modality\": \"image\"\n",
            "}\n",
            "{\n",
            "  \"input\": \"hate_audio.wav\",\n",
            "  \"expected\": \"Yes\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: audio\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \\\"Hate Speech: Yes\\\" or \\\"Hate Speech: No\\\"\\n   - Followed by \\\"\\u2014 Reason:\\\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <your detailed explanation with all tool outputs and reasoning>\\\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: hate_audio.wav\\n\\n\\nInput: hate_audio.wav\",\n",
            "    \"output\": \"Hate Speech: Yes \\u2014 Reason: The AudioHateChecker detected hate speech in the audio file \\\"hate_audio.wav\\\" with a confidence of 0.3586863974730174. The tool identified potentially hateful phrases.\"\n",
            "  },\n",
            "  \"modality\": \"audio\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nEvaluation Results:\")\n",
        "for res in eval_results:\n",
        "    print(json.dumps(res, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe input is text and appears to be in Hinglish. I will use the HinglishHateChecker and SentimentAnalyzer to analyze the text.\n",
            "Action: HinglishHateChecker\n",
            "Action Input: chutiyo logo ko mumbai me lena hi nhi chahiye\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-hinglish-text-model.hf.space ✔\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-hinglish-text-model.hf.space/config \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-hinglish-text-model.hf.space/info?serialize=False \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://dj-dawgs-ipd-ipd-hinglish-text-model.hf.space/queue/join \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-hinglish-text-model.hf.space/heartbeat/5a208fd7-056a-48c6-a665-8eeb2137f9ba \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-hinglish-text-model.hf.space/queue/data?session_hash=5a208fd7-056a-48c6-a665-8eeb2137f9ba \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mPrediction: OAG with a score of 0.9616120457649231\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe HinglishHateChecker has flagged the input as offensive, with a high score. I will now analyze the sentiment of the text.\n",
            "Action: SentimentAnalyzer\n",
            "Action Input: chutiyo logo ko mumbai me lena hi nhi chahiye\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m[[{'label': 'POSITIVE', 'score': 0.6149532794952393}, {'label': 'NEGATIVE', 'score': 0.38504672050476074}]]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe SentimentAnalyzer indicates a slightly positive sentiment. However, the HinglishHateChecker identified the text as offensive with a high confidence score. Given that the HinglishHateChecker flagged the text as offensive, I will classify it as hate speech.\n",
            "\n",
            "Hate Speech: Yes — Reason: The HinglishHateChecker classified the input text \"chutiyo logo ko mumbai me lena hi nhi chahiye\" as offensive (OAG) with a high score of 0.9616120457649231. Even though the sentiment analysis shows slightly positive sentiment, the hate speech detection tool indicates the presence of offensive content.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe HinglishHateChecker classified the input text \"chutiyo logo ko mumbai me lena hi nhi chahiye\" as offensive (OAG) with a high score of 0.9616120457649231. Even though the sentiment analysis shows slightly positive sentiment, the hate speech detection tool indicates the presence of offensive content.\n",
            "\n",
            "Hate Speech: Yes — Reason: The HinglishHateChecker classified the input text \"chutiyo logo ko mumbai me lena hi nhi chahiye\" as offensive (OAG) with a high score of 0.9616120457649231. Even though the sentiment analysis shows slightly positive sentiment, the hate speech detection tool indicates the presence of offensive content.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The HinglishHateChecker classified the input text \"chutiyo logo ko mumbai me lena hi nhi chahiye\" as offensive (OAG) with a high score of 0.9616120457649231.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The HinglishHateChecker classified the input text \"chutiyo logo ko mumbai me lena hi nhi chahiye\" as offensive (OAG) with a high score of 0.9616120457649231.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The HinglishHateChecker classified the input text \"chutiyo logo ko mumbai me lena hi nhi chahiye\" as offensive (OAG) with a high score of 0.9616120457649231.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The HinglishHateChecker classified the input text \"chutiyo logo ko mumbai me lena hi nhi chahiye\" as offensive (OAG) with a high score of 0.9616120457649231.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The HinglishHateChecker classified the input text \"chutiyo logo ko mumbai me lena hi nhi chahiye\" as offensive (OAG) with a high score of 0.9616120457649231.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The HinglishHateChecker classified the input text \"chutiyo logo ko mumbai me lena hi nhi chahiye\" as offensive (OAG) with a high score of 0.9616120457649231.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The HinglishHateChecker classified the input text \"chutiyo logo ko mumbai me lena hi nhi chahiye\" as offensive (OAG) with a high score of 0.9616120457649231. This indicates a high probability of the text being hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The HinglishHateChecker classified the input text \"chutiyo logo ko mumbai me lena hi nhi chahiye\" as offensive (OAG) with a high score of 0.9616120457649231. This indicates a high probability of the text being hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The HinglishHateChecker classified the input text \"chutiyo logo ko mumbai me lena hi nhi chahiye\" as offensive (OAG) with a high score of 0.9616120457649231. This indicates a high probability of the text being hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The HinglishHateChecker classified the input text \"chutiyo logo ko mumbai me lena hi nhi chahiye\" as offensive (OAG) with a high score of 0.9616120457649231. This indicates a high probability of the text being hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: Yes — Reason: The HinglishHateChecker classified the input text \"chutiyo logo ko mumbai me lena hi nhi chahiye\" as offensive (OAG) with a high score of 0.9616120457649231. This indicates a high probability of the text being hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe input is text. I should use the EnglishHateChecker and SentimentAnalyzer to analyze it.\n",
            "Action: EnglishHateChecker\n",
            "Action Input: I love the diverse culture of this city\u001b[0mLoaded as API: https://dj-dawgs-ipd-ipd-english-text-model.hf.space ✔\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-english-text-model.hf.space/config \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-english-text-model.hf.space/info?serialize=False \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://dj-dawgs-ipd-ipd-english-text-model.hf.space/queue/join \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-english-text-model.hf.space/heartbeat/1f50e6c2-0cd4-4afd-8b24-c45d1e9ccb48 \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://dj-dawgs-ipd-ipd-english-text-model.hf.space/queue/data?session_hash=1f50e6c2-0cd4-4afd-8b24-c45d1e9ccb48 \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mPrediction: NEITHER with a score of 0.9985595345497131\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe input is text. I should use the SentimentAnalyzer to analyze it.\n",
            "Action: SentimentAnalyzer\n",
            "Action Input: I love the diverse culture of this city\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m[[{'label': 'POSITIVE', 'score': 0.9998651742935181}, {'label': 'NEGATIVE', 'score': 0.00013480843335855752}]]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: No — Reason: The EnglishHateChecker classified the input as NEITHER with a high confidence score, and the SentimentAnalyzer classified it as POSITIVE with a very high confidence score. Therefore, the input does not constitute hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: No — Reason: The EnglishHateChecker classified the input as NEITHER with a high confidence score, and the SentimentAnalyzer classified it as POSITIVE with a very high confidence score. Therefore, the input does not constitute hate speech.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: No — Reason: The EnglishHateChecker classified the input as NEITHER with a high confidence score of 0.9985595345497131, and the SentimentAnalyzer classified it as POSITIVE with a very high confidence score of 0.9998651742935181. Therefore, the input does not constitute hate speech, as it expresses a positive sentiment towards cultural diversity.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: No — Reason: The EnglishHateChecker classified the input as NEITHER with a high confidence score of 0.9985595345497131, and the SentimentAnalyzer classified it as POSITIVE with a very high confidence score of 0.9998651742935181. Therefore, the input does not constitute hate speech, as it expresses a positive sentiment towards cultural diversity.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: No — Reason: The EnglishHateChecker classified the input as NEITHER with a high confidence score of 0.9985595345497131, and the SentimentAnalyzer classified it as POSITIVE with a very high confidence score of 0.9998651742935181. Therefore, the input does not constitute hate speech, as it expresses a positive sentiment towards cultural diversity.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: No — Reason: The EnglishHateChecker classified the input as NEITHER with a high confidence score of 0.9985595345497131, and the SentimentAnalyzer classified it as POSITIVE with a very high confidence score of 0.9998651742935181. Therefore, the input does not constitute hate speech, as it expresses a positive sentiment towards cultural diversity.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: No — Reason: The EnglishHateChecker classified the input as NEITHER with a high confidence score of 0.9985595345497131, and the SentimentAnalyzer classified it as POSITIVE with a very high confidence score of 0.9998651742935181. Therefore, the input does not constitute hate speech, as it expresses a positive sentiment towards cultural diversity.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: No — Reason: The EnglishHateChecker classified the input as NEITHER with a high confidence score of 0.9985595345497131, and the SentimentAnalyzer classified it as POSITIVE with a very high confidence score of 0.9998651742935181. Therefore, the input does not constitute hate speech, as it expresses a positive sentiment towards cultural diversity.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: No — Reason: The EnglishHateChecker classified the input as NEITHER with a high confidence score of 0.9985595345497131, and the SentimentAnalyzer classified it as POSITIVE with a very high confidence score of 0.9998651742935181. Therefore, the input does not constitute hate speech, as it expresses a positive sentiment towards cultural diversity.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:\u001b[32;1m\u001b[1;3mHate Speech: No — Reason: The EnglishHateChecker classified the input as NEITHER with a high confidence score of 0.9985595345497131, and the SentimentAnalyzer classified it as POSITIVE with a very high confidence score of 0.9998651742935181. Therefore, the input does not constitute hate speech, as it expresses a positive sentiment towards cultural diversity.\u001b[0m\n",
            "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
            "Thought:"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 17\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "ename": "ResourceExhausted",
          "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 14\n}\n]",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mResourceExhausted\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m eval_results, metrics = \u001b[43mextended_evaluate_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mextended_evaluate_pipeline\u001b[39m\u001b[34m(test_dataset, compute_metrics)\u001b[39m\n\u001b[32m     15\u001b[39m mem_before = process.memory_info().rss\n\u001b[32m     17\u001b[39m start_time = time.perf_counter()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m output = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m end_time = time.perf_counter()\n\u001b[32m     20\u001b[39m processing_time = end_time - start_time\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py:635\u001b[39m, in \u001b[36mtraceable.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(langsmith_extra, *args, **kwargs)\u001b[39m\n\u001b[32m    633\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m func_accepts_parent_run:\n\u001b[32m    634\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_tree\u001b[39m\u001b[33m\"\u001b[39m] = run_container[\u001b[33m\"\u001b[39m\u001b[33mnew_run\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m635\u001b[39m     function_result = \u001b[43mrun_container\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    637\u001b[39m     _cleanup_traceback(e)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(input_data)\u001b[39m\n\u001b[32m      4\u001b[39m     system_instruction = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33mYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\u001b[39m\n\u001b[32m      6\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m \u001b[33mInput: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_data\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     30\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msystem_instruction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mInput: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    169\u001b[39m     run_manager.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    171\u001b[39m run_manager.on_chain_end(outputs)\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:160\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    159\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    162\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    163\u001b[39m     )\n\u001b[32m    165\u001b[39m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    166\u001b[39m         inputs, outputs, return_only_outputs\n\u001b[32m    167\u001b[39m     )\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1624\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1622\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1623\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1624\u001b[39m     next_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1631\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1632\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1633\u001b[39m             next_step_output, intermediate_steps, run_manager=run_manager\n\u001b[32m   1634\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1330\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1321\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1322\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1323\u001b[39m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1327\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1328\u001b[39m ) -> Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1329\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m-> \u001b[39m\u001b[32m1330\u001b[39m         \u001b[43m[\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1340\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1330\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1321\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1322\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1323\u001b[39m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1327\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1328\u001b[39m ) -> Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1329\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m-> \u001b[39m\u001b[32m1330\u001b[39m         \u001b[43m[\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1340\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1358\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1355\u001b[39m     intermediate_steps = \u001b[38;5;28mself\u001b[39m._prepare_intermediate_steps(intermediate_steps)\n\u001b[32m   1357\u001b[39m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1358\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_action_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1364\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.handle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:804\u001b[39m, in \u001b[36mAgent.plan\u001b[39m\u001b[34m(self, intermediate_steps, callbacks, **kwargs)\u001b[39m\n\u001b[32m    792\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Given input, decided what to do.\u001b[39;00m\n\u001b[32m    793\u001b[39m \n\u001b[32m    794\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    801\u001b[39m \u001b[33;03m    Action specifying what tool to use.\u001b[39;00m\n\u001b[32m    802\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    803\u001b[39m full_inputs = \u001b[38;5;28mself\u001b[39m.get_full_inputs(intermediate_steps, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m804\u001b[39m full_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfull_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_parser.parse(full_output)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py:318\u001b[39m, in \u001b[36mLLMChain.predict\u001b[39m\u001b[34m(self, callbacks, **kwargs)\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks = \u001b[38;5;28;01mNone\u001b[39;00m, **kwargs: Any) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    304\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[32m    305\u001b[39m \n\u001b[32m    306\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    316\u001b[39m \u001b[33;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[32m    317\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m.output_key]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:188\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    186\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    187\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:389\u001b[39m, in \u001b[36mChain.__call__\u001b[39m\u001b[34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[32m    358\u001b[39m \n\u001b[32m    359\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    380\u001b[39m \u001b[33;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[32m    381\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    382\u001b[39m config = {\n\u001b[32m    383\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks,\n\u001b[32m    384\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m: tags,\n\u001b[32m    385\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    386\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m: run_name,\n\u001b[32m    387\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    169\u001b[39m     run_manager.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    171\u001b[39m run_manager.on_chain_end(outputs)\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:160\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    159\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    162\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    163\u001b[39m     )\n\u001b[32m    165\u001b[39m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    166\u001b[39m         inputs, outputs, return_only_outputs\n\u001b[32m    167\u001b[39m     )\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py:126\u001b[39m, in \u001b[36mLLMChain._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(\n\u001b[32m    122\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    123\u001b[39m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m    124\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    125\u001b[39m ) -> Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.create_outputs(response)[\u001b[32m0\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py:138\u001b[39m, in \u001b[36mLLMChain.generate\u001b[39m\u001b[34m(self, input_list, run_manager)\u001b[39m\n\u001b[32m    136\u001b[39m callbacks = run_manager.get_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm, BaseLanguageModel):\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    145\u001b[39m     results = \u001b[38;5;28mself\u001b[39m.llm.bind(stop=stop, **\u001b[38;5;28mself\u001b[39m.llm_kwargs).batch(\n\u001b[32m    146\u001b[39m         cast(List, prompts), {\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks}\n\u001b[32m    147\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:894\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    885\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    887\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    891\u001b[39m     **kwargs: Any,\n\u001b[32m    892\u001b[39m ) -> LLMResult:\n\u001b[32m    893\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:719\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    718\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    725\u001b[39m         )\n\u001b[32m    726\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    727\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:960\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    958\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    959\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    963\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    964\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1089\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1065\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1076\u001b[39m     **kwargs: Any,\n\u001b[32m   1077\u001b[39m ) -> ChatResult:\n\u001b[32m   1078\u001b[39m     request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   1079\u001b[39m         messages,\n\u001b[32m   1080\u001b[39m         stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1087\u001b[39m         tool_choice=tool_choice,\n\u001b[32m   1088\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m     response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:206\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    204\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:204\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[32m    201\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:188\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_with_retry\u001b[39m(**kwargs: Any) -> Any:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:867\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    864\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    866\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m867\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    875\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    289\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    290\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    292\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    164\u001b[39m     time.sleep(sleep)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    207\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    208\u001b[39m         error_list,\n\u001b[32m    209\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    210\u001b[39m         original_timeout,\n\u001b[32m    211\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    214\u001b[39m     on_error_fn(exc)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    146\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TIRATH BHATHAWALA\\Documents\\3rd Year\\sem6\\ml\\.venv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
            "\u001b[31mResourceExhausted\u001b[39m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 14\n}\n]"
          ]
        }
      ],
      "source": [
        "eval_results, metrics = extended_evaluate_pipeline(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation Results:\n",
            "{\n",
            "  \"input\": \"chutiyo logo ko mumbai me lena hi nhi chahiye\",\n",
            "  \"expected\": \"Yes\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: text\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \\\"Hate Speech: Yes\\\" or \\\"Hate Speech: No\\\"\\n   - Followed by \\\"\\u2014 Reason:\\\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <your detailed explanation with all tool outputs and reasoning>\\\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: chutiyo logo ko mumbai me lena hi nhi chahiye\\n\\n\\nInput: chutiyo logo ko mumbai me lena hi nhi chahiye\",\n",
            "    \"output\": \"Hate Speech: Yes \\u2014 Reason: The HinglishHateChecker flagged the input as offensive with a high score of 0.96, indicating a high probability of hate speech. While the sentiment analysis indicates a slightly positive sentiment, the derogatory nature of the words used outweighs this, leading to the conclusion that the input constitutes hate speech.\"\n",
            "  },\n",
            "  \"modality\": \"text\"\n",
            "}\n",
            "{\n",
            "  \"input\": \"I love the diverse culture of this city\",\n",
            "  \"expected\": \"No\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: text\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \\\"Hate Speech: Yes\\\" or \\\"Hate Speech: No\\\"\\n   - Followed by \\\"\\u2014 Reason:\\\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <your detailed explanation with all tool outputs and reasoning>\\\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: I love the diverse culture of this city\\n\\n\\nInput: I love the diverse culture of this city\",\n",
            "    \"output\": \"Hate Speech: No \\u2014 Reason: The EnglishHateChecker classified the input as NEITHER with a high confidence score, and the SentimentAnalyzer detected a highly positive sentiment. This suggests that the input does not contain hate speech.\"\n",
            "  },\n",
            "  \"modality\": \"text\"\n",
            "}\n",
            "{\n",
            "  \"input\": \"swastika.png\",\n",
            "  \"expected\": \"Yes\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: image\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \\\"Hate Speech: Yes\\\" or \\\"Hate Speech: No\\\"\\n   - Followed by \\\"\\u2014 Reason:\\\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <your detailed explanation with all tool outputs and reasoning>\\\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: swastika.png\\n\\n\\nInput: swastika.png\",\n",
            "    \"output\": \"Hate Speech: Yes \\u2014 Reason: The image contains a swastika, a symbol historically associated with Nazi Germany and hate, despite the tool classifying it as not hate. The context and potential for misinterpretation necessitate classifying it as hate speech.\"\n",
            "  },\n",
            "  \"modality\": \"image\"\n",
            "}\n",
            "{\n",
            "  \"input\": \"hate_audio.wav\",\n",
            "  \"expected\": \"Yes\",\n",
            "  \"output\": {\n",
            "    \"input\": \"\\nYou are an intelligent AI agent specialized in detecting hate speech. Your objective is to analyze the given input and decide if it constitutes hate speech.\\n\\nModality Detected: audio\\n\\nUse the following tools as applicable:\\n- For text inputs (both English and Hinglish): use the EnglishHateChecker and HinglishHateChecker to detect hate content, and use the SentimentAnalyzer to analyze sentiment.\\n- For image files: use the ImageHateChecker.\\n- For audio files: use the AudioHateChecker.\\n\\nInstructions:\\n1. **Input Analysis:** First, determine the modality of the input. If it is text, detect the language (English or Hinglish). Document your reasoning as a chain-of-thought.\\n2. **Tool Invocation:** Based on your analysis, invoke the appropriate tool(s). DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\n4. **Final Decision:** Using the consolidated outputs and your step-by-step reasoning, decide if the input is hate speech. Your final output must state:\\n   - \\\"Hate Speech: Yes\\\" or \\\"Hate Speech: No\\\"\\n   - Followed by \\\"\\u2014 Reason:\\\" and a comprehensive explanation that integrates all tool outputs and your reasoning.\\n\\nFinal Output Format:\\n\\\"Hate Speech: Yes/No \\u2014 Reason: <your detailed explanation with all tool outputs and reasoning>\\\"\\n\\nIMPORTANT: DO NOT REPEAT USING THE TOOLS IF THEY ARE NOT WORKING. SKIP OVER THEM AND USE YOUR OWN REASONING. \\nSOMETIMES THE TOOL MAY GIVE WRONG OUTPUT, SO TAKE INTO CONSIDERATION YOUR OWN REASONING AND DO NOT JUSTIFY THE OUTPUT BASED ON THE TOOL OUTPUT.\\n\\nNow, process the following input:\\nInput: hate_audio.wav\\n\\n\\nInput: hate_audio.wav\",\n",
            "    \"output\": \"Hate Speech: Yes \\u2014 Reason: The AudioHateChecker detected hate speech in the audio file \\\"hate_audio.wav\\\" with a confidence of 0.3586863974730174. The tool identified potentially hateful phrases.\"\n",
            "  },\n",
            "  \"modality\": \"audio\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nEvaluation Results:\")\n",
        "for res in eval_results:\n",
        "    print(json.dumps(res, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'metrics' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmetrics\u001b[49m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEvaluation Metrics:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(json.dumps(metrics, indent=\u001b[32m2\u001b[39m))\n",
            "\u001b[31mNameError\u001b[39m: name 'metrics' is not defined"
          ]
        }
      ],
      "source": [
        "if metrics:\n",
        "    print(\"\\nEvaluation Metrics:\")\n",
        "    print(json.dumps(metrics, indent=2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
